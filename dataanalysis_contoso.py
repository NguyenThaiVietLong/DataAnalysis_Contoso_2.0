import pandas as pd
import streamlit as st
from sklearn.ensemble import RandomForestRegressor
from package.dataStatistics import *
from package.preProcessing import *
from package.dataIntergration import *
from package.machineLearning import *
from package.visualizing import *
from st_pages import Page, Section, show_pages, add_page_title, hide_pages


add_page_title()

# @st.cache_data
# def load_data():
#     # data1 = pd.read_excel('data/2008 Contoso Data.xlsx')
#     # data2 = pd.read_excel('data/2009 Contoso Data.xlsx')
#     data1 = pd.read_json("data/jsonl/2008_Contoso_Data.jsonl", lines=True)
#     data2 = pd.read_json("data/jsonl/2009_Contoso_Data.jsonl", lines=True)
#     data = pd.concat([data1, data2], ignore_index=True)

#     data3 = pd.read_excel('data/excel/Contoso_Lookup_Tables.xlsx', sheet_name=None)
#     # data = pd.concat([data1, data2], ignore_index=True)

#     product_data = pd.read_json("data/jsonl/DIM_product.jsonl", lines=True)
#     # product_data = pd.read_excel('data/Contoso Lookup Tables.xlsx', sheet_name='DIM Product')
#     # product_subcategory_data = pd.read_excel('data/Contoso Lookup Tables.xlsx', sheet_name='DIM Product Sub Category')
#     product_subcategory_data = pd.read_json("data/jsonl/DIM_product_subcategory_data.jsonl", lines=True)
#     # geography_data = pd.read_excel('data/Contoso Lookup Tables.xlsx', sheet_name='DIM Geography')
#     geography_data = pd.read_json("data/jsonl/DIM_geography_data.jsonl", lines=True)
#     # channel_data =  pd.read_excel('data/Contoso Lookup Tables.xlsx', sheet_name='DIM Channel')
#     channel_data =  pd.read_json("data/jsonl/DIM_channel_data.jsonl", lines=True)
#     return data1,data2, data3, data, product_data, product_subcategory_data, geography_data, channel_data

# @st.cache_data
# def load_model():
#     new_data = dataReduction(data)
#     x = new_data.drop('SalesAmount',axis = 1)
#     y = new_data['SalesAmount']
#     x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42) 
#     # model_rf = RandomForestRegressor().fit(x_train, y_train)
#     model_lr = LinearRegression().fit(x_train, y_train)
#     model_gr = GradientBoostingRegressor().fit(x_train, y_train)
#     return model_gr, model_lr, new_data
# # Load data and random_forest model only once
# data1, data2,data3, data, product_data, product_subcategory_data, geography_data, channel_data = load_data()
# model_gr, model_lr, new_data = load_model()

# model_rf = LinearRegression().fit(x_train, y_train)


# HÃ m táº¡o liÃªn káº¿t Ä‘áº¿n cÃ¡c tab


# Táº¡o cÃ¡c tab trong sidebar
# tabs = ['Tab 1', 'Tab 2', 'Tab 3','Tab 4', 'Tab 5', 'Tab 6']
# selected_page = st.selectbox('Chá»n trang:', ['Trang 1', 'Trang 2', 'Trang 3','Trang 4', 'Trang 5', 'Trang 6','Trang 7', 'Trang 8', 'Trang 9','Trang 10', 'Trang 11', 'Trang 12','Trang 13','Trang 14','Trang 15','Trang 16','Trang 17', 'Trang 18'])
# pages = [
#     'Trang 1', 'Trang 2', 'Trang 3', 'Trang 4', 'Trang 5', 
#     'Trang 6', 'Trang 7', 'Trang 8', 'Trang 9', 'Trang 10', 
#     'Trang 11', 'Trang 12', 'Trang 13', 'Trang 14', 'Trang 15', 
#     'Trang 16', 'Trang 17', 'Trang 18'
# ]
# selected_page = st.sidebar.selectbox('Chá»n trang:', pages)

# Ná»™i dung cá»§a tab Ä‘Æ°á»£c chá»n
show_pages(
    [
        Page("main.py", "Data Analysis - Contoso", "ğŸ’»"),
        Page("main1.py", "Describe Dataset", "ğŸ’»"),
        Page("main2.py", "Data Statistics ", "ğŸ’»"),
        Page("main3.py", "Data Preprocessing ", "ğŸ’»"),
        Section( "Data Visualization ", "ğŸ’»"),
        Page("main.py", "Profit Contoso in 2008 - 2009 ", "ğŸ’»", in_section=True),
        Page("main.py", "Data Preprocessing ", "ğŸ’»", in_section=True),
        Page("main.py", "Why Decrease Revenue ", "ğŸ’»", in_section=True),
        Page("main.py", "Supplier's Profit ", "ğŸ’»", in_section=True),
        Page("main.py", "Quantity Sale by Class ", "ğŸ’»", in_section=True),
        Page("main.py", "Revenue by Class ", "ğŸ’»", in_section=True),
        Page("main.py", "Quantity Sold by Brand ", "ğŸ’»", in_section=True),
        Page("main.py", "Quantity Sales by Product Subcategory ", "ğŸ’»", in_section=True),
        Page("main.py", "Number of Stores by Region ", "ğŸ’»", in_section=True),
        Page("main.py", "Profit by Region ", "ğŸ’»", in_section=True),
        Page("main.py", "Revenues by Channel ", "ğŸ’»", in_section=True),
        Page("main.py", "Summary and Propose ", "ğŸ’»", in_section=True),
        Section( "Data Modeling ", "ğŸ’»"),
        Page("main.py", "Heatmap ", "ğŸ’»", in_section=True),
        Page("main.py", "Data Collection ", "ğŸ’»", in_section=True),
        Section( "Machine Learning ", "ğŸ’»"),
        Page("main.py", "Calculate model points ", "ğŸ’»", in_section=True),
        Page("main.py", "Test model against dataset ", "ğŸ’»", in_section=True),
        Page("main.py", "Demo model ", "ğŸ’»", in_section=True),

    ]
)
hide_pages(["Thank you"])

st.markdown("### ğŸ‘¨â€ğŸ”§ Data Analyst by Viá»‡t Long & SÆ¡n Lá»™c")

st.image("https://statics.cdn.200lab.io/2021/07/59-data-analysis-1.jpg")

st.info("Original Course Repository on [Github](https://github.com/DataTalksClub/data-engineering-zoomcamp)")

st.markdown("---")

with st.expander("Sign up here for 2024 Cohort"):
    st.markdown("""
    
    <a href="https://airtable.com/appzbS8Pkg9PL254a/shr6oVXeQvSI5HuWD"><img src="https://user-images.githubusercontent.com/875246/185755203-17945fd1-6b64-46f2-8377-1011dcb1a444.png" height="50" /></a>

    #

    - Register in [DataTalks.Club's Slack](https://datatalks.club/slack.html)
    - Join the [`#course-data-engineering`](https://app.slack.com/client/T01ATQK62F8/C01FABYF2RG) channel
    - Join the [course Telegram channel with announcements](https://t.me/dezoomcamp)
    - The videos are published on [DataTalks.Club's YouTube channel](https://www.youtube.com/c/DataTalksClub) in [the course playlist](https://www.youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb)
    - [Frequently asked technical questions](https://docs.google.com/document/d/19bnYs80DwuUimHM65UV3sylsCn2j1vziPOwzBwQrebw/edit?usp=sharing)
        
    #""", unsafe_allow_html=True)

st.markdown("""
### ğŸ‘¨â€ğŸ“ Taking the course

##### ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ 2024 Cohort

* **Start**: 15 January 2024 (Monday) at 17:00 CET
* **Registration link**: https://airtable.com/shr6oVXeQvSI5HuWD
* [Cohort folder](cohorts/2024/) with homeworks and deadlines 


##### ğŸ‘¨â€ğŸ”§ Self-paced mode

All the materials of the course are freely available, so that you
can take the course at your own pace

* Follow the suggested syllabus (see below) week by week
* You don't need to fill in the registration form. Just start watching the videos and join Slack
* Check [FAQ](https://docs.google.com/document/d/19bnYs80DwuUimHM65UV3sylsCn2j1vziPOwzBwQrebw/edit?usp=sharing) if you have problems
* If you can't find a solution to your problem in FAQ, ask for help in Slack

### ğŸ” Overview""", unsafe_allow_html=True)


st.image("https://raw.githubusercontent.com/DataTalksClub/data-engineering-zoomcamp/main/images/architecture/photo1700757552.jpeg")

# if selected_page  == 'Trang 1':

#     st.markdown('<h1 ">Má»¥c Lá»¥c</h1>', unsafe_allow_html=True)
#     st.header('1. MÃ” Táº¢ Vá»€ Bá»˜ Dá»® LIá»†U',anchor = 'Trang 2', )
#     st.header('2.THá»NG KÃŠ Dá»® LIá»†U',)
#     st.header('3. TIá»€N Xá»¬ LÃ Dá»® LIá»†U',)
#     st.header('4. TRá»°C QUAN HÃ“A Dá»® LIá»†U',)
#     st.header('5. MÃ” HÃŒNH HÃ“A Dá»® LIá»†U',)
#     st.header('6. Káº¾T LUáº¬N',)


# elif selected_page  == 'Trang 2':
#     st.header('MÃ” Táº¢ Vá»€ Bá»˜ Dá»® LIá»†U',divider = 'rainbow')
#     col1, col2 = st.columns(2)
#     col1.header('1. Company Background',)
#     col1.markdown("""
# <ul>
#   <li>Contoso lÃ  má»™t cÃ´ng ty bÃ¡n láº» Ä‘a quá»‘c gia</li>
#   <li>Thá»i gian: 2008 - 2009</li>
#   <li>Thá»‹ trÆ°á»ng: North America, Australia, Asia, Europe</li>
#   <li>KÃªnh phÃ¢n phá»‘i: Online, Store, Catalog, Reseller</li>
#   <li>Sáº£n pháº©m: Thiáº¿t bá»‹ Ä‘iá»‡n tá»­ vÃ  dá»‹ch vá»¥ media</li>
# </ul>
#  """, unsafe_allow_html=True)
#     col2.image('./Photo/2.jfif', caption='CÃ´ng ty Contoso', width=350)

#     st.header('2. MÃ´ hÃ¬nh Star Schema')
#     st.write('- Data Star Schema lÃ  má»™t mÃ´ hÃ¬nh tá»• chá»©c dá»¯ liá»‡u, nÆ¡i cÃ³ má»™t báº£ng trung tÃ¢m (fact table) Ä‘áº¡i diá»‡n cho sá»± kiá»‡n hoáº·c thÃ´ng tin cÆ¡ báº£n, Ä‘Æ°á»£c bao quanh bá»Ÿi cÃ¡c báº£ng chiá»u (dimension tables) mÃ´ táº£ chi tiáº¿t.\n\n- Äiá»ƒm máº¡nh cá»§a mÃ´ hÃ¬nh nÃ y náº±m á»Ÿ kháº£ nÄƒng tá»‘i Æ°u hiá»‡u suáº¥t truy váº¥n vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u.\n\n- CÃ¡c báº£ng chiá»u Ä‘Æ°á»£c tá»• chá»©c linh hoáº¡t vÃ  dá»… hiá»ƒu, giÃºp giáº£m thá»i gian xá»­ lÃ½, tÄƒng cÆ°á»ng kháº£ nÄƒng hiá»ƒn thá»‹ thÃ´ng tin, vÃ  há»— trá»£ má»Ÿ rá»™ng dá»¯ liá»‡u má»™t cÃ¡ch thuáº­n tiá»‡n.')   
#     st.image('./Photo/1.png', caption='MÃ´ hÃ¬nh Star Schema')
#     st.write(data)
#     tabs = st.tabs([sheet_name for sheet_name in data3.keys()])
#     for index, sheet_name in enumerate(data3.keys()):
#         with tabs[index]: 
#             st.write(data3[sheet_name])
    
    
# elif selected_page  == 'Trang 3':
#     st.header('THá»NG KÃŠ Dá»® LIá»†U',)
#     st.header('DATA 2008')
#     dataStatistics2008(data1)
#     st.header('DATA 2009')
#     dataStatistics2009(data2)


    
    
    

# elif selected_page   == 'Trang 4':
#     handleMissingData2008(data1)    
#     handleDuplicateData2008(data1)
#     checkDataType2008(data1)
#     handleMissingData2009(data2)
#     handleDuplicateData2009(data2)
#     checkDataType2009(data2)

#     dI_preProcessing(data)
    
# elif selected_page == 'Trang 5':
    
#     st.subheader('Lá»¢I NHUáº¬N NÄ‚M 2008 - 2009')
#     revenueOverTime(data1, data2)

# elif selected_page == 'Trang 6':
#     st.header('BÃ€I TOÃN: Táº I SAO Lá»¢I NHUáº¬N GIáº¢M')
#     col1, col2 = st.columns(2)
#     col1.image('./Photo/1496.jpg', caption='TÃ¬nh hÃ¬nh kinh táº¿ nÆ°á»›c Má»¹ cÃ¡c nÄƒm trÆ°á»›c 2010')
#     col2.image('./Photo/4.jpg', caption='Tá»· lá»‡ tháº¥t nghiá»‡p á»Ÿ Má»¹ nÄƒm 2009')

# elif selected_page == 'Trang 7':
    
#     st.header('TRá»°C QUAN HÃ“A Dá»® LIá»†U',)
#     st.subheader('1. DOANH THU Cá»¦A NHÃ€ CUNG Cáº¤P')
#     revenuebyManufacturer(data,product_data)
    
    
# elif selected_page == 'Trang 8':
#     quantitySalesByClass(data, product_data)
# elif selected_page == 'Trang 9':
#     st.subheader('4. Sá» LÆ¯á»¢NG Máº¶T HÃ€NG THEO THÆ¯Æ NG HIá»†U')
#     quantitySoldByBrand(data, product_data)
# elif selected_page == 'Trang 10':
#     st.subheader('5. Sá» LÆ¯á»¢NG Máº¶T HÃ€NG THEO LOáº I Sáº¢N PHáº¨M')
#     quantitySalesByProductSub(product_data, product_subcategory_data,data)
# elif selected_page == 'Trang 11':
#     st.subheader('5. Sá» LÆ¯á»¢NG Cá»¬A HÃ€NG THEO KHU Vá»°C')
#     storeCount(geography_data)
#     st.subheader('6. Lá»¢I NHUáº¬N THEO KHU Vá»°C')
#     profitByQuarterForAll(data, geography_data)
# elif selected_page == 'Trang 12':
#     st.subheader('7. DOANH THU THEO KÃŠNH BÃN HÃ€NG')
#     revenueByChannelPieChart(data, channel_data)
#     revenueByYearForCatalog(data, channel_data)

# elif selected_page == 'Trang 13':
#     st.header('Äá»€ XUáº¤T',)
#     st.subheader('- Táº­p trung cÃ¡c sáº£n pháº©m tiá»‡n lá»£i, dá»… sá»­ dá»¥ng ')
#     st.subheader('- Má»Ÿ rá»™ng thá»‹ trÆ°á»ng ChÃ¢u Ã ')
#     st.subheader('- PhÃ¡t triá»ƒn kÃªnh bÃ¡n hÃ ng trá»±c tuyáº¿n ')


# elif selected_page == 'Trang 14':
#     st.header('MÃ” HÃŒNH HÃ“A Dá»® LIá»†U',)
#     heatMap(data)
    



# elif selected_page == 'Trang 15':
#     st.header('THU GIáº¢M Dá»® LIá»†U',)
#     data = dataReduction(data)
#     st.write(data)
# elif selected_page == 'Trang 16':
#     st.header('MÃ” HÃŒNH HÃ“A Dá»® LIá»†U',)
#     data = dataReduction(data)
#     machineLearning(data)


# elif selected_page == 'Trang 17':
#     st.header('KIá»‚M TRA Bá»˜ Dá»® LIá»†U',)
#     predictValue(data=new_data, model_gr = model_gr, model_lr = model_lr)

# elif selected_page == 'Trang 18':
#     st.header('DEMO',)
#     predictValue2(model_gr)










# TÃ­nh ma tráº­n tÆ°Æ¡ng quan
#    
